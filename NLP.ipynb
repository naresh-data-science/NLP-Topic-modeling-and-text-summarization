{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70420d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f39125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we are only interested in text column so we will use it only\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv(r\"D:\\DataScience\\Class\\Assignments\\NLP Text mining\\tweets.csv\")\n",
    "\n",
    "tweets.head(10)\n",
    "\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "# let us import the regular expression library re\n",
    "\n",
    "import re\n",
    "\n",
    "# let us now define some characters that have to be cleaned\n",
    "\n",
    "HANDLE = '@\\w+'\n",
    "\n",
    "LINK = 'https?://t\\.co/\\w+'\n",
    "\n",
    "SPECIAL_CHARS = '&lt;|&lt;|&amp;|#'\n",
    "\n",
    "# defining funtion to clean our text tweets\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(HANDLE, ' ', text)\n",
    "    text = re.sub(LINK, ' ', text)\n",
    "    text = re.sub(SPECIAL_CHARS, ' ', text)\n",
    "    return text\n",
    "\n",
    "# applying the clean function to text column and saving it back\n",
    "\n",
    "tweets['Text'] = tweets.Tweets.apply(clean)\n",
    "\n",
    "tweets.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have removed or clean the data from unwanted words like @,%,&, virgin america etc.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd296818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After that we will use Gensimâ€™s Dictionary constructor to give each word in the tweet corpus a unique integer identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed97614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# making each observation as list of words present in that tweet\n",
    "\n",
    "tweets = tweets.Text.apply(preprocess_string).tolist()\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "import gensim\n",
    "\n",
    "# making a Dictionary object from gensim library and using it creating corpus\n",
    "\n",
    "dictionary = corpora.dictionary.Dictionary(tweets)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in tweets]\n",
    "\n",
    "# creating LdaModel class object using corpus dataset\n",
    "\n",
    "\n",
    "NUM_TOPICS = 5\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10)\n",
    "\n",
    "ldamodel.print_topics(num_words=5)\n",
    "\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "def calculate_coherence_score(documents, dictionary, model):\n",
    "    coherence_model = CoherenceModel(model=model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "\n",
    "def get_coherence_values(start, stop):\n",
    "    for num_topics in range(start, stop):\n",
    "        print(f'\\nCalculating coherence for {num_topics} topics')\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = num_topics, id2word=dictionary, passes=2)\n",
    "        coherence = calculate_coherence_score(tweets, dictionary, ldamodel)\n",
    "        yield coherence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting an LDA model in Gensim is quite simple. As a starting point, we have fit a model with 10 topics to 16 topics and now we calculate coherence scores from 10 topics to 16 topics using the function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae95a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016b167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e6832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afecf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736e4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56917a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dada08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93706530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab08d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
